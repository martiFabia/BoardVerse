{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. threads.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import uuid\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repositories\n",
    "DATA_DIR = os.path.join(\"..\", \"data\")\n",
    "TEMP_DIR = os.path.join(DATA_DIR, \"temp\")\n",
    "RAW_DIR = os.path.join(DATA_DIR, \"raw\")\n",
    "MONGO_DIR = os.path.join(DATA_DIR, \"clean\", \"mongo\")\n",
    "NEO4J_DIR = os.path.join(DATA_DIR, \"clean\", \"neo4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repos creation\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "os.makedirs(MONGO_DIR, exist_ok=True)\n",
    "os.makedirs(NEO4J_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "MAP_FILE = os.path.join(TEMP_DIR, \"user_map.json\")\n",
    "RECENT_REVIEWS = os.path.join(TEMP_DIR, \"recent_reviews.json\")\n",
    "\n",
    "FORUMS_FILE = os.path.join(RAW_DIR, \"forums.json\")\n",
    "BOARD_GAMES_FILE = os.path.join(RAW_DIR, \"boardgames&reviews.json\")\n",
    "\n",
    "GAMES_JSON = os.path.join(MONGO_DIR, \"games.json\")\n",
    "THREADS_JSON = os.path.join(MONGO_DIR, \"threads.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(data, filename):\n",
    "    \"\"\"\n",
    "    Save data to a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    data (any): The data to be saved to the JSON file. This can be any data type that is serializable to JSON.\n",
    "    filename (str): The name of the file where the data will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_json(new_data, filename):\n",
    "    \"\"\"\n",
    "    Adds new data to an existing JSON file without duplicates.\n",
    "\n",
    "        new_data (list): The new data to add.\n",
    "        filename (str): The name of the JSON file.\n",
    "    \"\"\"\n",
    "    # Read existing data from the file.\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            existing_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        existing_data = []\n",
    "\n",
    "    # Combine the existing data with the new data and remove duplicates.\n",
    "    combined_data = {json.dumps(item, sort_keys=True): item for item in existing_data + new_data}.values()\n",
    "\n",
    "    # Save the combined data back to the file.\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(list(combined_data), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_html(content, length):\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    truncated_content = ''\n",
    "    current_length = 0\n",
    "\n",
    "    for element in soup.recursiveChildGenerator():\n",
    "        if isinstance(element, str):\n",
    "            if current_length + len(element) > length:\n",
    "                truncated_content += element[:length - current_length]\n",
    "                break\n",
    "            else:\n",
    "                truncated_content += element\n",
    "                current_length += len(element)\n",
    "        else:\n",
    "            truncated_content += str(element)\n",
    "    \n",
    "    return truncated_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 15:44:35,414 - INFO - Loaded 2000 games.\n",
      "2025-01-20 15:44:55,523 - INFO - Loaded 302 forums.\n",
      "2025-01-20 15:44:55,759 - INFO - Loaded 121274 users.\n"
     ]
    }
   ],
   "source": [
    "with open(BOARD_GAMES_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_games = [ \n",
    "        {\n",
    "            \"id\": int(raw_game[\"id\"]), \n",
    "            \"name\": raw_game[\"name\"],\n",
    "            \"yearReleased\": raw_game[\"yearReleased\"] if raw_game[\"yearReleased\"] >= 0 else 0\n",
    "        } \n",
    "        for raw_game in json.load(f)\n",
    "    ]\n",
    "with open(GAMES_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    clean_games = [ \n",
    "        {\n",
    "            \"id\": game[\"id\"], \n",
    "            \"name\": game[\"name\"],\n",
    "            \"yearReleased\": game[\"yearReleased\"]\n",
    "        } \n",
    "        for game in json.load(f)\n",
    "    ]\n",
    "game_dict = {}\n",
    "for raw_game in raw_games:\n",
    "    for clean_game in clean_games:\n",
    "        if raw_game[\"name\"] == clean_game[\"name\"] and raw_game[\"yearReleased\"] == clean_game[\"yearReleased\"]:\n",
    "            game_dict[raw_game[\"id\"]] = clean_game\n",
    "            break\n",
    "logger.info(f\"Loaded {len(game_dict)} games.\")\n",
    "\n",
    "with open(FORUMS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_forums = json.load(f)\n",
    "logger.info(f\"Loaded {len(raw_forums)} forums.\")\n",
    "\n",
    "with open(MAP_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    user_map = json.load(f)\n",
    "logger.info(f\"Loaded {len(user_map)} users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing threads:   0%|          | 0/302 [00:00<?, ?it/s]C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_14712\\3383130392.py:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(raw_message[\"content\"], \"html.parser\")\n",
      "C:\\Users\\Utente\\AppData\\Local\\Temp\\ipykernel_14712\\1069377992.py:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(content, 'html.parser')\n",
      "Processing threads: 100%|██████████| 302/302 [05:55<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "threads = []\n",
    "\n",
    "for raw_game in tqdm(raw_forums, desc=\"Processing threads\"):\n",
    "    for raw_forum in raw_game[\"forums\"]:\n",
    "        for raw_thread in raw_forum[\"threads\"]:\n",
    "            if raw_thread[\"author\"] not in user_map:\n",
    "                continue\n",
    "            thread = {\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"author\": user_map[raw_thread[\"author\"]],\n",
    "                \"content\": raw_thread[\"subject\"],\n",
    "                \"postDate\": datetime.strptime(raw_thread[\"post_date\"], \"%a, %d %b %Y %H:%M:%S %z\").isoformat(),\n",
    "                \"lastPostDate\": None,\n",
    "                \"tag\": raw_forum[\"title\"],\n",
    "                \"game\": game_dict[raw_game[\"id\"]],\n",
    "                \"messages\": []\n",
    "            }\n",
    "\n",
    "            # Add messages and update last post date\n",
    "            for raw_message in raw_thread[\"messages\"]:\n",
    "                if raw_message[\"username\"] not in user_map:\n",
    "                    continue\n",
    "                message = {\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"author\": user_map[raw_message[\"username\"]],\n",
    "                    \"postDate\": datetime.strptime(raw_message[\"post_date\"], \"%Y-%m-%dT%H:%M:%S%z\").isoformat(),\n",
    "                    \"content\": None\n",
    "                }\n",
    "\n",
    "                # Manage message content\n",
    "                if raw_message[\"content\"] is None:\n",
    "                    continue\n",
    "                soup = BeautifulSoup(raw_message[\"content\"], \"html.parser\")\n",
    "                font_tag = soup.find(\"font\", {\"color\": \"#2121A4\"})\n",
    "                if font_tag:\n",
    "                    html_reply = str(font_tag)\n",
    "                    font_tag.decompose()\n",
    "\n",
    "                    # Extract reply info\n",
    "                    reply_soup = BeautifulSoup(html_reply, 'html.parser')\n",
    "                    if reply_soup.find('div', class_='quotetitle'):\n",
    "                        username_tag = reply_soup.find('div', class_='quotetitle').find('b')\n",
    "                        username = re.search(r'^(.*) wrote:', username_tag.text).group(1)\n",
    "                        body_tag = reply_soup.find('div', class_='quotebody').find('i')\n",
    "                        body_content = body_tag.decode_contents()\n",
    "                        \n",
    "                        if username in user_map:\n",
    "                            username = user_map[username]\n",
    "                            # Search the reply message in previous messages\n",
    "                            for prev_message in thread[\"messages\"]:\n",
    "                                if prev_message[\"author\"] == username and (body_content.strip() in prev_message[\"content\"].strip()):\n",
    "                                    message[\"replyTo\"] = {\n",
    "                                        \"username\": prev_message[\"author\"],\n",
    "                                        \"messageUUID\": prev_message['id'],\n",
    "                                        \"contentPreview\": truncate_html(prev_message[\"content\"], 100)  # Insert only the first 100 characters of the message\n",
    "                                    }\n",
    "                                    break\n",
    "\n",
    "                message[\"content\"] = str(soup)\n",
    "\n",
    "                thread[\"messages\"].append(message)\n",
    "                thread[\"lastPostDate\"] = max(message[\"postDate\"], thread[\"lastPostDate\"]) if thread[\"lastPostDate\"] else message[\"postDate\"]\n",
    "            \n",
    "            threads.append(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 16:00:11,862 - INFO - Saved 9665 threads to ..\\data\\clean\\mongo\\threads.json.\n"
     ]
    }
   ],
   "source": [
    "if threads:\n",
    "    save_to_json(threads, THREADS_JSON)\n",
    "logger.info(f\"Saved {len(threads)} threads to {THREADS_JSON}.\")\n",
    "threads = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
